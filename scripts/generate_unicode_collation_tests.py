#!/usr/bin/env python
# -*- coding: utf-8 -*-

from generate_unicode_normalization_data import cccs
from generate_unicode_normalization_data import expand_decomp_canonical
from generate_unicode_normalization_data import get_decompositions
from generate_unicode_collation_data import get_ducet
from generate_unicode_collation_data import ce_to_cpp

import re

lookup_tests_form = '''\
// Warning! This file is autogenerated.
#include <boost/text/collation_data.hpp>

#include <boost/algorithm/cxx14/equal.hpp>

#include <gtest/gtest.h>


{0}
'''

lookup_perf_test_form = decls = '''\
// Warning! This file is autogenerated.
#include <boost/text/collation_data.hpp>

#include <benchmark/benchmark.h>

{0}

BENCHMARK_MAIN()
'''

verbatim_collation_tests_form = '''\
// Warning! This file is autogenerated.
#include "collation_tests.hpp"

#include <boost/algorithm/cxx14/equal.hpp>

#include <gtest/gtest.h>


{0}
'''

def indices_to_list(indices, all_cps):
    return all_cps[indices[0]:indices[1]]

def generate_lookup_tests(ducet, ducet_lines):
    chunk_size = 150

    cccs_dict = cccs('DerivedCombiningClass.txt')
    (all_cps, decomposition_mapping) = \
      get_decompositions('UnicodeData.txt', cccs_dict, expand_decomp_canonical, True)

    reverse_decompositions = {}
    for k,v in decomposition_mapping:
        if 1 < len(v):
            reverse_decompositions[tuple(indices_to_list(v, all_cps))] = (k,)

    lines = ''
    chunk = 0
    i = 0
    for k,v in sorted(ducet.items()):
        initial_k = k
        if k in reverse_decompositions:
            k = reverse_decompositions[k]
        lines += '''
TEST(collation, table_lookup_{0:03}_{1:03})
{{
    // {2}
    // {3}

    uint32_t const cps[{5}] = {{ {4} }};{8}
    // biased L2 weight
    boost::text::compressed_collation_element const ces[{7}] = {{ {6} }};

    auto const coll = boost::text::longest_collation(cps, cps + {5});

    EXPECT_TRUE(coll.node_.collation_elements_);
    EXPECT_EQ(coll.match_length_, {5});
    EXPECT_TRUE(boost::algorithm::equal(coll.node_.collation_elements_.begin(), coll.node_.collation_elements_.end(), ces, ces + {7}));
}}
'''.format(
    chunk, i, ducet_lines[initial_k][0], ducet_lines[initial_k][1],
    ', '.join(map(lambda x: hex(x), k)), len(k),
    ', '.join(map(lambda x: ce_to_cpp(x, min_l2), v)), len(v),
    k != initial_k and ' // Expands to the code points in the comment above.' or ''
    )
        i += 1
        if i == chunk_size:
            cpp_file = open('collation_element_lookup_{0:03}.cpp'.format(chunk), 'w')
            cpp_file.write(lookup_tests_form.format(lines))
            lines = ''
            chunk += 1
            i = 0

    cpp_file = open('collation_element_lookup_{0:03}.cpp'.format(chunk), 'w')
    cpp_file.write(lookup_tests_form.format(lines))

def generate_lookup_perf_test(ducet):
    chunk_size = 50
    chunks_per_file = 100

    chunk_arrays = []

    chunk = 0
    i = 0
    cps = []
    cp_ranges = []
    for k,v in sorted(ducet.items()):
        cp_ranges.append((len(cps), len(cps) + len(k)))
        cps += list(k)
        i += 1
        if i == chunk_size:
            chunk_arrays.append((cps, cp_ranges))
            chunk += 1
            i = 0
            cps = []
            cp_ranges = []

    chunk_idx = 0
    lines = ''
    for i in range(len(chunk_arrays)):
        if i != 0 and i % chunks_per_file == 0:
            cpp_file = open('collation_element_lookup_perf_{0:03}.cpp'.format(chunk_idx), 'w')
            cpp_file.write(lookup_perf_test_form.format(lines))
            chunk_idx += 1
            lines = ''
        cps = chunk_arrays[i][0]
        cp_ranges = chunk_arrays[i][1]
        lines += '''\
uint32_t cps_{0:03}[] = {{
{1}
}};

void BM_collation_element_lookup_{0:03}(benchmark::State & state)
{{
    while (state.KeepRunning()) {{
'''.format(i, ', '.join(map(lambda x: hex(x), cps)), len(cps), '// TODO')
        for first,last in cp_ranges:
            lines += '''\
            benchmark::DoNotOptimize(boost::text::longest_collation(cps_{0:03} + {1}, cps_{0:03} + {2}));
'''.format(i, first, last)
        lines += '''\
    }}
}}
BENCHMARK(BM_collation_element_lookup_{0:03});

'''.format(i)

    cpp_file = open('collation_element_lookup_perf_{0:03}.cpp'.format(chunk_idx), 'w')
    cpp_file.write(lookup_perf_test_form.format(lines))

collation_elements_regex = re.compile(r'\[([ |0123456789ABCDEF]+)\]')

def generate_collation_tests(non_ignorable_filename, shifted_filename):
    non_ignorable_lines = open(non_ignorable_filename, 'r').readlines()

    shifted = {}

    shifted_lines = open(shifted_filename, 'r').readlines()
    for line in shifted_lines:
        line = line[:-1]
        if not line.startswith('#') and len(line) != 0:
            comment_start = line.find('#')
            shifted_comment = ''
            if comment_start != -1:
                shifted_comment = line[comment_start + 1:].strip()
                line = line[:comment_start]
            cps = map(lambda x: '0x' + x, line.split(';')[0].split(' '))
            ces_match = collation_elements_regex.search(shifted_comment)
            ces = ces_match.group(1).replace('|', '0000').split(' ')
            ces = ces[:-1]
            ces_shifted = map(lambda x: '0x' + x, ces)
            shifted[tuple(cps)] = (shifted_comment, ces_shifted)

    contents = ''
    chunk_idx = 0
    line_idx = 0 
    for i in range(len(non_ignorable_lines)):
        non_ignorable_line = non_ignorable_lines[i]
        if line_idx == 500:
            cpp_file = open('verbatim_collation_test_{0:03}.cpp'.format(chunk_idx), 'w')
            cpp_file.write(verbatim_collation_tests_form.format(contents))
            chunk_idx += 1
            contents = ''
            line_idx = 0
        non_ignorable_line = non_ignorable_line[:-1]
        if not non_ignorable_line.startswith('#') and len(non_ignorable_line) != 0:
            comment_start = non_ignorable_line.find('#')
            non_ignorable_comment = ''
            if comment_start != -1:
                non_ignorable_comment = non_ignorable_line[comment_start + 1:].strip()
                non_ignorable_line = non_ignorable_line[:comment_start]
            if 'surrogate' in non_ignorable_comment:
                continue
            if 'noncharacter' in non_ignorable_comment:
                continue
            cps = map(lambda x: '0x' + x, non_ignorable_line.split(';')[0].split(' '))
            ces_match = collation_elements_regex.search(non_ignorable_comment)
            ces = ces_match.group(1).replace('|', '0000').split(' ')
            ces = ces[:-1]
            ces_non_ignorable = map(lambda x: '0x' + x, ces)

            (shifted_comment, ces_shifted) = shifted[tuple(cps)]

            contents += '''
TEST(collation, verbatim_{1:03}_{2:03})
{{
    uint32_t const cps[{6}] = {{ {5} }};

    // {3}
    uint32_t const ces_non_ignorable[{8}] = {{ {7} }};

    auto const non_ignorable = collate_for_tests(
        cps, cps + {6}, boost::text::variable_weighting::non_ignorable,
        boost::text::collation_strength::tertiary);

    EXPECT_EQ(non_ignorable.size(), {8});
    EXPECT_TRUE(boost::algorithm::equal(non_ignorable.begin(), non_ignorable.end(), ces_non_ignorable, ces_non_ignorable + {8}))
        << "from:     " << ce_dumper(cps)
        << "expected: " << ce_dumper(ces_non_ignorable)
        << "got:      " << ce_dumper(non_ignorable);

    // {4}
    uint32_t const ces_shifted[{10}] = {{ {9} }};

    auto const shifted = collate_for_tests(
        cps, cps + {6}, boost::text::variable_weighting::shifted,
        boost::text::collation_strength::quaternary);

    EXPECT_EQ(shifted.size(), {10});
    EXPECT_TRUE(boost::algorithm::equal(shifted.begin(), shifted.end(), ces_shifted, ces_shifted + {10}))
        << "from:     " << ce_dumper(cps)
        << "expected: " << ce_dumper(ces_shifted)
        << "got:      " << ce_dumper(shifted);
}}
'''.format(
    None, chunk_idx, line_idx,
    non_ignorable_line + '\n    // ' + non_ignorable_comment,
    non_ignorable_line + '\n    // ' + shifted_comment,
    ', '.join(cps), len(cps),
    ', '.join(ces_non_ignorable), len(ces_non_ignorable),
    ', '.join(ces_shifted), len(ces_shifted)
    )
            line_idx += 1

    if contents != '':
        cpp_file = open('verbatim_collation_test_{0:03}.cpp'.format(chunk_idx), 'w')
        cpp_file.write(verbatim_collation_tests_form.format(contents))

# TODO: Consider using allkeys_CLDR.txt.
(ducet, ducet_lines, min_var, max_var, min_l1, max_l1, min_l2, max_l2, min_l3, max_l3) = \
  get_ducet('allkeys.txt')

import sys
if '--perf' in sys.argv:
    generate_lookup_perf_test(ducet)
    exit(0)

generate_lookup_tests(ducet, ducet_lines)
generate_collation_tests('CollationTest_NON_IGNORABLE.txt', 'CollationTest_SHIFTED.txt')
